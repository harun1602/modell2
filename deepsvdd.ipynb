{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-15T23:24:33.518660Z",
     "start_time": "2025-06-15T23:24:28.156541Z"
    }
   },
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from pyod.models.deep_svdd import DeepSVDD\n",
    "\n",
    "normal_path = \"transients/S01/1/Normal/q_data\"\n",
    "relay_path  = \"transients/S01/1/Relay/q_data\"\n",
    "\n",
    "with h5py.File(\"datasets/transients_cleaned_padded.h5\", \"r\") as f:\n",
    "    normal_group = f[normal_path]\n",
    "    relay_group  = f[relay_path]\n",
    "\n",
    "    n_norm = normal_group[\"0\"].shape[0]\n",
    "    n_relay = relay_group[\"0\"].shape[0]\n",
    "\n",
    "    dataset_normal = np.zeros((49666, n_norm))\n",
    "    dataset_relay  = np.zeros((49666, n_relay))\n",
    "\n",
    "    for i in range(49666):\n",
    "        try:\n",
    "            dataset_normal[i] = normal_group[str(i)][:]\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    for i in range(49666):\n",
    "        try:\n",
    "            dataset_relay[i] = relay_group[str(i)][:]\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "scalerMinMax = MinMaxScaler()\n",
    "scalerStandard = StandardScaler()\n",
    "\n",
    "X_train               = dataset_normal[:47500]\n",
    "X_test_normal         = dataset_normal[47500:]\n",
    "X_test_relay          = dataset_relay[47500:]\n",
    "\n",
    "scalerMinMax.fit(X_train)\n",
    "X_train_scaled_minmax       = scalerMinMax.transform(X_train)\n",
    "X_test_norm_scaled_minmax   = scalerMinMax.transform(X_test_normal)\n",
    "X_test_relay_scaled_minmax  = scalerMinMax.transform(X_test_relay)\n",
    "\n",
    "scalerStandard.fit(X_train)\n",
    "X_train_scaled_standard        = scalerStandard.transform(X_train)\n",
    "X_test_norm_scaled_standard    = scalerStandard.transform(X_test_normal)\n",
    "X_test_relay_scaled_standard   = scalerStandard.transform(X_test_relay)\n",
    "\n",
    "X_test_combined = np.vstack((X_test_normal, X_test_relay))\n",
    "X_test_combined_scaled_minmax = np.vstack((X_test_norm_scaled_minmax, X_test_relay_scaled_minmax))\n",
    "X_test_combined_scaled_standard = np.vstack((X_test_norm_scaled_standard, X_test_relay_scaled_standard))\n",
    "\n",
    "y_true = np.array([0] * len(X_test_normal) + [1] * len(X_test_relay))"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:24:33.919900Z",
     "start_time": "2025-06-15T23:24:33.620009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for n in {(64, 32), (128, 64), (256, 128)}:\n",
    "    for d in {0.01, 0.1, 0.2}:\n",
    "            clf = DeepSVDD(contamination=0.01, hidden_neurons=n, dropout_rate=d, n_features=173)\n",
    "            clf.fit(X_train)\n",
    "\n",
    "            # pyod.predict: 0 = inlier, 1 = outlier\n",
    "            y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "            # cm und report\n",
    "            cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "            print(f\"hidden neuron {n}\")\n",
    "            print(f\"dropout {d}\")\n",
    "            print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, target_names=[\"Normal\",\"Relay\"]))\n",
    "\n",
    "            # plot\n",
    "            plt.figure(figsize=(6,5))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "                        xticklabels=[\"Relay\",\"Normal\"],\n",
    "                        yticklabels=[\"Relay\",\"Normal\"],\n",
    "                        cbar=False)\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "            plt.title(\"Konfusionsmatrix\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ],
   "id": "2e87a80cc7163fe3",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (47500x151 and 173x64)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.2\u001B[39m}:\n\u001B[1;32m      3\u001B[0m         clf \u001B[38;5;241m=\u001B[39m DeepSVDD(contamination\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, hidden_neurons\u001B[38;5;241m=\u001B[39mn, dropout_rate\u001B[38;5;241m=\u001B[39md, n_features\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m173\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m         \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m         \u001B[38;5;66;03m# pyod.predict: 0 = inlier, 1 = outlier\u001B[39;00m\n\u001B[1;32m      7\u001B[0m         y_pred \u001B[38;5;241m=\u001B[39m clf\u001B[38;5;241m.\u001B[39mpredict(X_test_combined)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyod/models/deep_svdd.py:320\u001B[0m, in \u001B[0;36mDeepSVDD.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m--> 320\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_c\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_norm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[38;5;66;03m# Predict on X itself and calculate the reconstruction error as\u001B[39;00m\n\u001B[1;32m    323\u001B[0m \u001B[38;5;66;03m# the outlier scores. Noted X_norm was shuffled has to recreate\u001B[39;00m\n\u001B[1;32m    324\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocessing:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyod/models/deep_svdd.py:94\u001B[0m, in \u001B[0;36mInnerDeepSVDD._init_c\u001B[0;34m(self, X_norm, eps)\u001B[0m\n\u001B[1;32m     88\u001B[0m intermediate_output \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     89\u001B[0m hook_handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39m_modules\u001B[38;5;241m.\u001B[39mget(\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnet_output\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mregister_forward_hook(\n\u001B[1;32m     91\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m module, \u001B[38;5;28minput\u001B[39m, output: intermediate_output\u001B[38;5;241m.\u001B[39mupdate(\n\u001B[1;32m     92\u001B[0m         {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnet_output\u001B[39m\u001B[38;5;124m'\u001B[39m: output})\n\u001B[1;32m     93\u001B[0m )\n\u001B[0;32m---> 94\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_norm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m out \u001B[38;5;241m=\u001B[39m intermediate_output[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnet_output\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     97\u001B[0m hook_handle\u001B[38;5;241m.\u001B[39mremove()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 250\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (47500x151 and 173x64)"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for n in {(64, 32), (128, 64), (256, 128)}:\n",
    "    for d in {0.01, 0.1, 0.2}:\n",
    "            clf = DeepSVDD(contamination=0.01, hidden_neurons=n, dropout_rate=d, n_features=173)\n",
    "            clf.fit(X_train_scaled_standard)\n",
    "\n",
    "            # pyod.predict: 0 = inlier, 1 = outlier\n",
    "            y_pred = clf.predict(X_test_combined_scaled_standard)\n",
    "\n",
    "            # cm und report\n",
    "            cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "            print(f\"hidden neuron {n}\")\n",
    "            print(f\"dropout {d}\")\n",
    "            print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, target_names=[\"Normal\",\"Relay\"]))\n",
    "\n",
    "            # plot\n",
    "            plt.figure(figsize=(6,5))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "                        xticklabels=[\"Relay\",\"Normal\"],\n",
    "                        yticklabels=[\"Relay\",\"Normal\"],\n",
    "                        cbar=False)\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "            plt.title(\"Konfusionsmatrix\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ],
   "id": "c574845ccdf7ff39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for n in {(64, 32), (128, 64), (256, 128)}:\n",
    "    for d in {0.1, 0.2, 0.3}:\n",
    "            clf = DeepSVDD(contamination=0.01, hidden_neurons=n, dropout_rate=d, n_features=173, epochs=250)\n",
    "            clf.fit(X_train_scaled_standard)\n",
    "\n",
    "            # pyod.predict: 0 = inlier, 1 = outlier\n",
    "            y_pred = clf.predict(X_test_combined_scaled_standard)\n",
    "\n",
    "            # cm und report\n",
    "            cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "            print(f\"hidden neuron {n}\")\n",
    "            print(f\"dropout {d}\")\n",
    "            print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, target_names=[\"Normal\",\"Relay\"]))\n",
    "\n",
    "            # plot\n",
    "            plt.figure(figsize=(6,5))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "                        xticklabels=[\"Relay\",\"Normal\"],\n",
    "                        yticklabels=[\"Relay\",\"Normal\"],\n",
    "                        cbar=False)\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "            plt.title(\"Konfusionsmatrix\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ],
   "id": "8370eb1121f7f680",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for n in {(64, 32), (128, 64), (256, 128)}:\n",
    "    for d in {0.01, 0.1, 0.2}:\n",
    "        clf = DeepSVDD(contamination=0.01, hidden_neurons=n, dropout_rate=d, n_features=173)\n",
    "        clf.fit(X_train_scaled_minmax)\n",
    "\n",
    "        # pyod.predict: 0 = inlier, 1 = outlier\n",
    "        y_pred = clf.predict(X_test_combined_scaled_minmax)\n",
    "\n",
    "        # cm und report\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "        print(f\"hidden neuron {n}\")\n",
    "        print(f\"dropout {d}\")\n",
    "        print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, target_names=[\"Normal\",\"Relay\"]))\n",
    "\n",
    "        # plot\n",
    "        plt.figure(figsize=(6,5))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "                    xticklabels=[\"Relay\",\"Normal\"],\n",
    "                    yticklabels=[\"Relay\",\"Normal\"],\n",
    "                    cbar=False)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(\"Konfusionsmatrix\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "id": "46ce5afe3b16b4a9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
